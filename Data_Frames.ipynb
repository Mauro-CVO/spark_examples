{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "from pyspark.sql.types import Row, StringType, FloatType\n",
    "\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar Sesion de Spark\n",
    "\n",
    "spark = SparkContext(master='local', appName='DataFrames')\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\r\n",
      "deportista2.csv  evento.csv\t      paises.csv\r\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\r\n",
      "1,1896 Verano,1896,Verano,Athina\r\n",
      "2,1900 Verano,1900,Verano,Paris\r\n",
      "3,1904 Verano,1904,Verano,St. Louis\r\n",
      "4,1906 Verano,1906,Verano,Athina\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 files/juegos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el schema en el cual se alojaran los datos\n",
    "\n",
    "games_schema = StructType([\n",
    "    StructField('game_id', IntegerType(),False),\n",
    "    StructField('year', StringType(), False),\n",
    "    StructField('season', StringType(), False),\n",
    "    StructField('city',StringType(),False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar DataFrame apartir del archivo y el schema creado\n",
    "\n",
    "games_DF = sqlContext.read.schema(games_schema)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/juegos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------+------+\n",
      "|game_id|       year|season|  city|\n",
      "+-------+-----------+------+------+\n",
      "|      1|1896 Verano|  1896|Verano|\n",
      "|      2|1900 Verano|  1900|Verano|\n",
      "|      3|1904 Verano|  1904|Verano|\n",
      "|      4|1906 Verano|  1906|Verano|\n",
      "+-------+-----------+------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games_DF.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrames</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=DataFrames>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear DF apartir de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_athlete_RDD = spark.textFile(\"files/deportista.csv\") \\\n",
    "    .map(lambda l: l.split(','))\n",
    "olympic_athlete2_RDD = spark.textFile(\"files/deportista2.csv\") \\\n",
    "    .map(lambda l : l.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_athlete_RDD = olympic_athlete_RDD \\\n",
    "    .union(olympic_athlete2_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympic_athlete_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(index, iterator):\n",
    "    return iter(list(iterator)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_athlete_RDD = olympic_athlete_RDD.mapPartitionsWithIndex(remove_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278'],\n",
       " ['5', 'Christine Jacoba Aaftink', '2', '21', '185', '82', '705']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olympic_athlete_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_athlete_RDD = olympic_athlete_RDD.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    int(l[2]),\n",
    "    int(l[3]),\n",
    "    int(l[4]),\n",
    "    float(l[5]),\n",
    "    int(l[6])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|athlete_id|                name|gender|age|height|weight|team_id|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|         1|           A Dijiang|     1| 24|   180|  80.0|    199|\n",
      "|         2|            A Lamusi|     1| 23|   170|  60.0|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     1| 24|     0|   0.0|    273|\n",
      "|         4|Edgar Lindenau Aabye|     1| 34|     0|   0.0|    278|\n",
      "|         5|Christine Jacoba ...|     2| 21|   185|  82.0|    705|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"athlete_id\", IntegerType(),False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"gender\", IntegerType(), False),\n",
    "    StructField(\"age\", IntegerType(), False),\n",
    "    StructField(\"height\", IntegerType(), False),\n",
    "    StructField(\"weight\", FloatType(), False),\n",
    "    StructField(\"team_id\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "athlete_DF = sqlContext.createDataFrame(olympic_athlete_RDD, schema)\n",
    "athlete_DF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando DataFrames apartir de archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+\n",
      "|team_id|           team_name|country|\n",
      "+-------+--------------------+-------+\n",
      "|      1|         30. Februar|    AUT|\n",
      "|      2|A North American ...|    MEX|\n",
      "|      3|           Acipactli|    MEX|\n",
      "|      4|             Acturus|    ARG|\n",
      "|      5|         Afghanistan|    AFG|\n",
      "+-------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_teams = StructType([\n",
    "    StructField(\"team_id\", IntegerType(),False),\n",
    "    StructField(\"team_name\", StringType(), False),\n",
    "    StructField(\"country\", StringType(), False)\n",
    "])\n",
    "\n",
    "teams_DF = sqlContext.read.schema(schema_teams)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/paises.csv\")\n",
    "\n",
    "teams_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+-------+--------+\n",
      "|result_id|medal|athlete_id|game_id|event_id|\n",
      "+---------+-----+----------+-------+--------+\n",
      "|        1|   NA|         1|     39|       1|\n",
      "|        2|   NA|         2|     49|       2|\n",
      "|        3|   NA|         3|      7|       3|\n",
      "|        4| Gold|         4|      2|       4|\n",
      "|        5|   NA|         5|     36|       5|\n",
      "+---------+-----+----------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_medals = StructType([\n",
    "    StructField(\"result_id\", IntegerType(),False),\n",
    "    StructField(\"medal\", StringType(), False),\n",
    "    StructField(\"athlete_id\", IntegerType(), False),\n",
    "    StructField(\"game_id\", IntegerType(), False),\n",
    "    StructField(\"event_id\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "medals_DF = sqlContext.read.schema(schema_medals)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/resultados.csv\")\n",
    "\n",
    "medals_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|sport_id|        sport|\n",
      "+--------+-------------+\n",
      "|       1|   Basketball|\n",
      "|       2|         Judo|\n",
      "|       3|     Football|\n",
      "|       4|   Tug-Of-War|\n",
      "|       5|Speed Skating|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_sports = StructType([\n",
    "    StructField(\"sport_id\", IntegerType(),False),\n",
    "    StructField(\"sport\", StringType(), False),\n",
    "])\n",
    "\n",
    "sports_DF = sqlContext.read.schema(schema_sports)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/deporte.csv\")\n",
    "\n",
    "sports_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+\n",
      "|event_id|          event_name|sport_id|\n",
      "+--------+--------------------+--------+\n",
      "|       1|Basketball Men's ...|       1|\n",
      "|       2|Judo Men's Extra-...|       2|\n",
      "|       3|Football Men's Fo...|       3|\n",
      "|       4|Tug-Of-War Men's ...|       4|\n",
      "|       5|Speed Skating Wom...|       5|\n",
      "+--------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_events = StructType([\n",
    "    StructField(\"event_id\", IntegerType(),False),\n",
    "    StructField(\"event_name\", StringType(), False),\n",
    "    StructField(\"sport_id\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "events_DF = sqlContext.read.schema(schema_events)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/evento.csv\")\n",
    "\n",
    "events_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----+------+---------+\n",
      "|game_id|year-season|year|season|     city|\n",
      "+-------+-----------+----+------+---------+\n",
      "|      1|1896 Verano|1896|Verano|   Athina|\n",
      "|      2|1900 Verano|1900|Verano|    Paris|\n",
      "|      3|1904 Verano|1904|Verano|St. Louis|\n",
      "|      4|1906 Verano|1906|Verano|   Athina|\n",
      "|      5|1908 Verano|1908|Verano|   London|\n",
      "+-------+-----------+----+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(game_id=1, year-season='1896 Verano', year='1896', season='Verano', city='Athina'),\n",
       " Row(game_id=2, year-season='1900 Verano', year='1900', season='Verano', city='Paris'),\n",
       " Row(game_id=3, year-season='1904 Verano', year='1904', season='Verano', city='St. Louis')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_games = StructType([\n",
    "    StructField(\"game_id\", IntegerType(),False),\n",
    "    StructField(\"year-season\", StringType(), False),\n",
    "    StructField(\"year\", StringType(), False),\n",
    "    StructField(\"season\", StringType(), False),\n",
    "    StructField(\"city\", StringType(), False),\n",
    "])\n",
    "\n",
    "games_DF = sqlContext.read.schema(schema_games)\\\n",
    "    .option(\"header\", \"true\").csv(\"files/juegos.csv\")\n",
    "\n",
    "games_DF.show(5)\n",
    "games_DF.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imprimir el Schema nos permite visualizar de forma general la estructura del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sport_id: integer (nullable = true)\n",
      " |-- sport: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sports_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- height: integer (nullable = false)\n",
      " |-- weight: float (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- sex: integer (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- weight: float (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF = athlete_DF.withColumnRenamed('gender','sex').drop('height')\n",
    "\n",
    "athlete_DF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existen diferentes funciones de pyspark que nos permiten realizar operaciones con los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_DF = athlete_DF\\\n",
    "    .select(\"athlete_id\", \"name\", col(\"age\").alias(\"age_in_competition\"), \"team_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+-------+\n",
      "|athlete_id|                name|age_in_competition|team_id|\n",
      "+----------+--------------------+------------------+-------+\n",
      "|         1|           A Dijiang|                24|    199|\n",
      "|         2|            A Lamusi|                23|    199|\n",
      "|         3| Gunnar Nielsen Aaby|                24|    273|\n",
      "|         4|Edgar Lindenau Aabye|                34|    278|\n",
      "|         5|Christine Jacoba ...|                21|    705|\n",
      "+----------+--------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar DF con las condiciones que pongamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_DF = athlete_DF.filter((athlete_DF.age_in_competition != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+-------+\n",
      "|athlete_id|                name|age_in_competition|team_id|\n",
      "+----------+--------------------+------------------+-------+\n",
      "|     71691|  Dimitrios Loundras|                10|    333|\n",
      "|     52070|        Etsuko Inada|                11|    514|\n",
      "|     40129|    Luigina Giavotti|                11|    507|\n",
      "|     37333|Carlos Bienvenido...|                11|    982|\n",
      "|     47618|Sonja Henie Toppi...|                11|    742|\n",
      "+----------+--------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF.sort(\"age_in_competition\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupaciones y operaciones Joins sobre DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- team_id: integer (nullable = true)\n",
      " |-- team_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- age_in_competition: integer (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF.printSchema()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- result_id: integer (nullable = true)\n",
      " |-- medal: string (nullable = true)\n",
      " |-- athlete_id: integer (nullable = true)\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- event_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- year-season: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "games_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sport_id: integer (nullable = true)\n",
      " |-- sport: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sports_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: integer (nullable = true)\n",
      " |-- event_name: string (nullable = true)\n",
      " |-- sport_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+----------------+--------------------+\n",
      "|                name|age_in_competition|medal|competition_year|          event_name|\n",
      "+--------------------+------------------+-----+----------------+--------------------+\n",
      "|           A Dijiang|                24|   NA|            1992|Basketball Men's ...|\n",
      "|            A Lamusi|                23|   NA|            2012|Judo Men's Extra-...|\n",
      "| Gunnar Nielsen Aaby|                24|   NA|            1920|Football Men's Fo...|\n",
      "|Edgar Lindenau Aabye|                34| Gold|            1900|Tug-Of-War Men's ...|\n",
      "|Christine Jacoba ...|                21|   NA|            1994|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|                21|   NA|            1994|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|                21|   NA|            1992|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|                21|   NA|            1992|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|                21|   NA|            1988|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|                21|   NA|            1988|Speed Skating Wom...|\n",
      "|     Per Knut Aaland|                31|   NA|            1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1994|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1992|Cross Country Ski...|\n",
      "|     Per Knut Aaland|                31|   NA|            1992|Cross Country Ski...|\n",
      "|        John Aalberg|                31|   NA|            1994|Cross Country Ski...|\n",
      "|        John Aalberg|                31|   NA|            1994|Cross Country Ski...|\n",
      "+--------------------+------------------+-----+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_DF.join(medals_DF, athlete_DF.athlete_id == medals_DF.athlete_id,\"left\")\\\n",
    "    .join(games_DF, games_DF.game_id == medals_DF.game_id,\"left\")\\\n",
    "    .join(events_DF, events_DF.event_id == medals_DF.event_id,\"left\")\\\n",
    "    .select(athlete_DF.name, athlete_DF.age_in_competition, medals_DF.medal, \n",
    "            col('year').alias(\"competition_year\"), events_DF.event_name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio, DF con las medallas ganadoras, pais y equipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame de las filtrado de las medallas ganadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+-------+--------+\n",
      "|result_id| medal|athlete_id|game_id|event_id|\n",
      "+---------+------+----------+-------+--------+\n",
      "|        4|  Gold|         4|      2|       4|\n",
      "|       38|Bronze|        15|      7|      19|\n",
      "|       39|Bronze|        15|      7|      20|\n",
      "|       41|Bronze|        16|     50|      14|\n",
      "|       42|Bronze|        17|     17|      21|\n",
      "|       43|  Gold|        17|     17|      22|\n",
      "|       45|  Gold|        17|     17|      24|\n",
      "|       49|  Gold|        17|     17|      28|\n",
      "|       51|Bronze|        17|     19|      22|\n",
      "|       61|  Gold|        20|     38|      32|\n",
      "|       62|Bronze|        20|     38|      33|\n",
      "|       64|Silver|        20|     40|      31|\n",
      "|       65|Bronze|        20|     40|      32|\n",
      "|       68|Silver|        20|     40|      35|\n",
      "|       74|  Gold|        20|     44|      32|\n",
      "|       77|  Gold|        20|     44|      35|\n",
      "|       79|  Gold|        20|     46|      32|\n",
      "|       80|  Gold|        21|     47|      36|\n",
      "|       87|Silver|        25|      7|      41|\n",
      "|       92|Bronze|        29|     37|      45|\n",
      "+---------+------+----------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals_winned = medals_DF.filter(medals_DF.medal != \"NA\")\n",
    "medals_winned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Entre DF medallas ganadas, paises y equipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_team_counrty = teams_DF.join(athlete_DF, teams_DF.team_id == athlete_DF.team_id, \"left\")\\\n",
    "    .join(medals_winned, athlete_DF.athlete_id == medals_winned.athlete_id, \"left\")\\\n",
    "    .select(medals_winned.medal, teams_DF.team_name, teams_DF.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------+\n",
      "| medal|     team_name|country|\n",
      "+------+--------------+-------+\n",
      "|  Gold|Denmark/Sweden|    SWE|\n",
      "|Bronze|       Finland|    FIN|\n",
      "|Bronze|       Finland|    FIN|\n",
      "|Bronze|       Finland|    FIN|\n",
      "|Bronze|       Finland|    FIN|\n",
      "|  Gold|       Finland|    FIN|\n",
      "|  Gold|       Finland|    FIN|\n",
      "|  Gold|       Finland|    FIN|\n",
      "|Bronze|       Finland|    FIN|\n",
      "|  Gold|        Norway|    NOR|\n",
      "|  Gold|        Norway|    NOR|\n",
      "|  Gold|        Norway|    NOR|\n",
      "|Silver|        Norway|    NOR|\n",
      "|Bronze|        Norway|    NOR|\n",
      "|Silver|        Norway|    NOR|\n",
      "|Bronze|        Norway|    NOR|\n",
      "|  Gold|        Norway|    NOR|\n",
      "|  Gold|        Norway|    NOR|\n",
      "|Silver|        Norway|    NOR|\n",
      "|Bronze|   Netherlands|    NED|\n",
      "+------+--------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medal_team_counrty.filter(medal_team_counrty.medal != \"NA\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de agregacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_per_year = athlete_DF\\\n",
    "    .join(medals_DF, athlete_DF.athlete_id == medals_DF.athlete_id, \"left\")\\\n",
    "    .join(games_DF, games_DF.game_id == medals_DF.game_id,\"left\")\\\n",
    "    .join(teams_DF, athlete_DF.team_id == teams_DF.team_id, \"left\")\\\n",
    "    .join(events_DF, events_DF.event_id == medals_DF.event_id,\"left\")\\\n",
    "    .join(sports_DF, events_DF.sport_id == sports_DF.sport_id, \"left\")\\\n",
    "    .select(teams_DF.country, games_DF.year, medals_DF.medal,\n",
    "           events_DF.event_name, sports_DF.sport, athlete_DF.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------------------+--------------------+--------------------+\n",
      "|country|year|medal|          event_name|               sport|                name|\n",
      "+-------+----+-----+--------------------+--------------------+--------------------+\n",
      "|    CHN|1992|   NA|Basketball Men's ...|          Basketball|           A Dijiang|\n",
      "|    CHN|2012|   NA|Judo Men's Extra-...|                Judo|            A Lamusi|\n",
      "|    DEN|1920|   NA|Football Men's Fo...|            Football| Gunnar Nielsen Aaby|\n",
      "|    SWE|1900| Gold|Tug-Of-War Men's ...|          Tug-Of-War|Edgar Lindenau Aabye|\n",
      "|    NED|1994|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    NED|1994|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    NED|1992|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    NED|1992|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    NED|1988|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    NED|1988|   NA|Speed Skating Wom...|       Speed Skating|Christine Jacoba ...|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1992|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1992|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1992|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1992|   NA|Cross Country Ski...|Cross Country Skiing|     Per Knut Aaland|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "|    USA|1994|   NA|Cross Country Ski...|Cross Country Skiing|        John Aalberg|\n",
      "+-------+----+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "winner_per_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_country_per_year = winner_per_year.filter(winner_per_year.medal != \"NA\")\\\n",
    "    .sort(\"year\")\\\n",
    "    .groupBy(\"country\",\"year\",\"event_name\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- event_name: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medal_country_per_year.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------+------------------+\n",
      "|country|year|total_medals|       medals_mean|\n",
      "+-------+----+------------+------------------+\n",
      "|    USA|1896|          20|1.6666666666666667|\n",
      "|    GER|1896|          30|               2.5|\n",
      "|    GBR|1896|           8|1.1428571428571428|\n",
      "|    FRA|1896|          11|             1.375|\n",
      "|    GRE|1896|           9|1.2857142857142858|\n",
      "|    HUN|1896|           6|               1.0|\n",
      "|    AUS|1896|           3|               1.0|\n",
      "|    AUT|1896|           5|               1.0|\n",
      "|    DEN|1896|           6|               1.0|\n",
      "|    SUI|1896|           3|               1.0|\n",
      "|    SWE|1900|           6|               3.0|\n",
      "|    USA|1900|          65|2.4074074074074074|\n",
      "|    FRA|1900|         179| 3.314814814814815|\n",
      "|    GER|1900|          27|               4.5|\n",
      "|    NOR|1900|           9|               1.8|\n",
      "|    GBR|1900|          68|2.8333333333333335|\n",
      "|    HUN|1900|           5|               1.0|\n",
      "|    SUI|1900|          21|               3.5|\n",
      "|    NED|1900|          26| 4.333333333333333|\n",
      "|    BEL|1900|          21|1.6153846153846154|\n",
      "+-------+----+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medal_country_per_year.groupBy('country', 'year')\\\n",
    "    .agg(sum('count').alias(\"total_medals\"),avg(\"count\").alias(\"medals_mean\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar SQL de forma nativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar DataFrames como tablas SQL\n",
    "\n",
    "medals_DF.registerTempTable(\"medals\")\n",
    "athlete_DF.registerTempTable(\"athlete\")\n",
    "teams_DF.registerTempTable(\"teams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+-------+\n",
      "|athlete_id|                name|age_in_competition|team_id|\n",
      "+----------+--------------------+------------------+-------+\n",
      "|         1|           A Dijiang|                24|    199|\n",
      "|         2|            A Lamusi|                23|    199|\n",
      "|         3| Gunnar Nielsen Aaby|                24|    273|\n",
      "|         4|Edgar Lindenau Aabye|                34|    278|\n",
      "|         5|Christine Jacoba ...|                21|    705|\n",
      "+----------+--------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM athlete\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+----------+-------+--------+\n",
      "|result_id|medal|athlete_id|game_id|event_id|\n",
      "+---------+-----+----------+-------+--------+\n",
      "|        1|   NA|         1|     39|       1|\n",
      "|        2|   NA|         2|     49|       2|\n",
      "|        3|   NA|         3|      7|       3|\n",
      "|        4| Gold|         4|      2|       4|\n",
      "|        5|   NA|         5|     36|       5|\n",
      "+---------+-----+----------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM medals\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+\n",
      "|team_id|           team_name|country|\n",
      "+-------+--------------------+-------+\n",
      "|      1|         30. Februar|    AUT|\n",
      "|      2|A North American ...|    MEX|\n",
      "|      3|           Acipactli|    MEX|\n",
      "|      4|             Acturus|    ARG|\n",
      "|      5|         Afghanistan|    AFG|\n",
      "+-------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT * FROM teams\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------+\n",
      "| medal|team_name|country|\n",
      "+------+---------+-------+\n",
      "|  Gold| Zimbabwe|    ZIM|\n",
      "|Silver| Zimbabwe|    ZIM|\n",
      "|  Gold| Zimbabwe|    ZIM|\n",
      "|Silver| Zimbabwe|    ZIM|\n",
      "|Silver| Zimbabwe|    ZIM|\n",
      "+------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT medal,team_name, country FROM medals m\n",
    "    JOIN athlete a\n",
    "    ON m.athlete_id = a.athlete_id\n",
    "    JOIN teams t\n",
    "    ON t.team_id = a.team_id\n",
    "    WHERE medal <> \"NA\"\n",
    "    ORDER BY country DESC\n",
    "    \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrames</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=DataFrames>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF (User Defined Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\r\n",
      "deportista2.csv  evento.csv\t      paises.csv\r\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\r\n",
      "1,A Dijiang,1,24,180,80,199\r\n",
      "2,A Lamusi,1,23,170,60,199\r\n",
      "3,Gunnar Nielsen Aaby,1,24,,,273\r\n",
      "4,Edgar Lindenau Aabye,1,34,,,278\r\n",
      "5,Christine Jacoba Aaftink,2,21,185,82,705\r\n",
      "6,Per Knut Aaland,1,31,188,75,1096\r\n",
      "7,John Aalberg,1,31,183,72,1096\r\n",
      "8,\"Cornelia \"\"Cor\"\" Aalten (-Strannood)\",2,18,168,,705\r\n",
      "9,Antti Sami Aalto,1,26,186,96,350\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 files/deportistaError.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_error_RDD = spark.textFile(\"files/deportistaError.csv\")\\\n",
    "    .map(lambda l: l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_error_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_header(index, iterator):\n",
    "    return iter(list(iterator)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_error_RDD = athlete_error_RDD.mapPartitionsWithIndex(delete_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '', '', '273']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_error_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_error_RDD = athlete_error_RDD.map(lambda l:\n",
    "    (l[0], l[1], l[2], l[3], l[4], l[5], l[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_athlete_error = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"gender\", StringType(), False),\n",
    "    StructField(\"age\", StringType(), False),\n",
    "    StructField(\"height\", StringType(), False),\n",
    "    StructField(\"weight\", StringType(), False),\n",
    "    StructField(\"team_id\", StringType(), False),\n",
    "])\n",
    "\n",
    "athlete_error_DF = sqlContext.createDataFrame(athlete_error_RDD, schema_athlete_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+---+------+------+-------+\n",
      "| id|                name|gender|age|height|weight|team_id|\n",
      "+---+--------------------+------+---+------+------+-------+\n",
      "|  1|           A Dijiang|     1| 24|   180|    80|    199|\n",
      "|  2|            A Lamusi|     1| 23|   170|    60|    199|\n",
      "|  3| Gunnar Nielsen Aaby|     1| 24|      |      |    273|\n",
      "|  4|Edgar Lindenau Aabye|     1| 34|      |      |    278|\n",
      "|  5|Christine Jacoba ...|     2| 21|   185|    82|    705|\n",
      "|  6|     Per Knut Aaland|     1| 31|   188|    75|   1096|\n",
      "|  7|        John Aalberg|     1| 31|   183|    72|   1096|\n",
      "|  8|\"Cornelia \"\"Cor\"\"...|     2| 18|   168|      |    705|\n",
      "|  9|    Antti Sami Aalto|     1| 26|   186|    96|    350|\n",
      "| 10|\"Einar Ferdinand ...|     1| 26|      |      |    350|\n",
      "| 11|  Jorma Ilmari Aalto|     1| 22|   182|  76.5|    350|\n",
      "| 12|   Jyri Tapani Aalto|     1| 31|   172|    70|    350|\n",
      "| 13|  Minna Maarit Aalto|     2| 30|   159|  55.5|    350|\n",
      "| 14|Pirjo Hannele Aal...|     2| 32|   171|    65|    350|\n",
      "| 15|Arvo Ossian Aaltonen|     1| 22|      |      |    350|\n",
      "| 16|Juhamatti Tapio A...|     1| 28|   184|    85|    350|\n",
      "| 17|Paavo Johannes Aa...|     1| 28|   175|    64|    350|\n",
      "| 18|Timo Antero Aaltonen|     1| 31|   189|   130|    350|\n",
      "| 19|Win Valdemar Aalt...|     1| 54|      |      |    350|\n",
      "| 20|  Kjetil Andr Aamodt|     1| 20|   176|    85|    742|\n",
      "+---+--------------------+------+---+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_error_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(value):\n",
    "    return int(value) if len(value) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(z)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_int_UDF = udf(lambda z: to_int(z), IntegerType())\n",
    "sqlContext.udf.register(\"to_int_UDF\", to_int_UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|height_UDF|\n",
      "+----------+\n",
      "|       180|\n",
      "|       170|\n",
      "|      null|\n",
      "|      null|\n",
      "|       185|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_error_DF.select(to_int_UDF(\"height\").alias(\"height_UDF\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionado y Persistencia de datos\n",
    "#### Documentacion\n",
    "https://spark.apache.org/docs/2.4.6/api/python/pyspark.html#pyspark.StorageLevel\n",
    "\n",
    "https://spark.apache.org/docs/2.4.6/api/python/pyspark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[222] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o794.persist.\n: java.lang.UnsupportedOperationException: Cannot change storage level of an RDD after it was already assigned a level\n\tat org.apache.spark.rdd.RDD.persist(RDD.scala:170)\n\tat org.apache.spark.rdd.RDD.persist(RDD.scala:195)\n\tat org.apache.spark.api.java.JavaRDD.persist(JavaRDD.scala:47)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-31207f4eab16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmedal_country_per_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorageLevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMEMORY_AND_DISK_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(self, storageLevel)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mjavaStorageLevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getJavaStorageLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorageLevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaStorageLevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o794.persist.\n: java.lang.UnsupportedOperationException: Cannot change storage level of an RDD after it was already assigned a level\n\tat org.apache.spark.rdd.RDD.persist(RDD.scala:170)\n\tat org.apache.spark.rdd.RDD.persist(RDD.scala:195)\n\tat org.apache.spark.api.java.JavaRDD.persist(JavaRDD.scala:47)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "medal_country_per_year.rdd.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[222] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[222] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Percistencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "StorageLevel.MEMORY_AND_DISK_3 = StorageLevel(True,True,False,False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[222] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[222] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(True, True, False, False, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medal_country_per_year.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Partition\")\\\n",
    "    .master(\"local[5]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(0,20)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = spark.sparkContext.parallelize((0,20), 10)\n",
    "rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar archivos con particiones especificas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_from_file = spark.sparkContext.textFile(\"files/deporte.csv\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_from_file.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_from_file.saveAsTextFile(\"files/rdd_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000  part-00002\tpart-00004  part-00006\tpart-00008  _SUCCESS\r\n",
      "part-00001  part-00003\tpart-00005  part-00007\tpart-00009\r\n"
     ]
    }
   ],
   "source": [
    "!ls files/rdd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte_id,deporte\r\n",
      "1,Basketball\r\n",
      "2,Judo\r\n",
      "3,Football\r\n",
      "4,Tug-Of-War\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 files/rdd_info/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,Athletics\r\n",
      "8,Ice Hockey\r\n",
      "9,Swimming\r\n",
      "10,Badminton\r\n",
      "11,Sailing\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 files/rdd_info/part-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar archivos desde particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.wholeTextFiles(\"files/rdd_info/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/home/mau/Documents/spark_project/files/rdd_info/part-00007',\n",
       "  '47,Beach Volleyball\\n48,Triathlon\\n49,Ski Jumping\\n50,Curling\\n51,Snowboarding\\n52,Rugby\\n53,Short Track Speed Skating\\n'),\n",
       " ('file:/home/mau/Documents/spark_project/files/rdd_info/part-00000',\n",
       "  'deporte_id,deporte\\n1,Basketball\\n2,Judo\\n3,Football\\n4,Tug-Of-War\\n5,Speed Skating\\n6,Cross Country Skiing\\n'),\n",
       " ('file:/home/mau/Documents/spark_project/files/rdd_info/part-00004',\n",
       "  '29,Cycling\\n30,Diving\\n31,Canoeing\\n32,Tennis\\n33,Modern Pentathlon\\n34,Figure Skating\\n35,Golf\\n'),\n",
       " ('file:/home/mau/Documents/spark_project/files/rdd_info/part-00001',\n",
       "  '7,Athletics\\n8,Ice Hockey\\n9,Swimming\\n10,Badminton\\n11,Sailing\\n12,Biathlon\\n13,Gymnastics\\n14,Art Competitions\\n')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rdd = rdd.mapValues(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rdd = [l[0] for l in list_rdd]\n",
    "list_rdd.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file:/home/mau/Documents/spark_project/files/rdd_info/part-00000',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00001',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00002',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00003',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00004',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00005',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00006',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00007',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00008',\n",
       " 'file:/home/mau/Documents/spark_project/files/rdd_info/part-00009']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = spark.sparkContext.textFile(','.join(list_rdd),10)\\\n",
    "    .map(lambda l : l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deporte_id', 'deporte'],\n",
       " ['1', 'Basketball'],\n",
       " ['2', 'Judo'],\n",
       " ['3', 'Football'],\n",
       " ['4', 'Tug-Of-War']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
